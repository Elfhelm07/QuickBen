{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwMkk5Z2aL3n",
        "outputId": "b2ec6a92-db02-4ecb-cd9a-0b058819ed98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-0nwqmp1z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-0nwqmp1z\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1+cu121)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=1956927b1aba5859ec1d672caf5fe541de7f56317c4a8fa859b8deb8879c91ab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2peho3r2/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: pydub, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 pydub-0.25.1 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy pydub git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to extract audio from video\n",
        "def extract_audio(video_file, output_audio_file):\n",
        "    print(\"Extracting audio from video...\")\n",
        "    video = VideoFileClip(video_file)\n",
        "    audio = video.audio\n",
        "    audio.write_audiofile(output_audio_file)\n",
        "    print(f\"Audio extracted to {output_audio_file}\")\n",
        "\n",
        "# Function to convert audio to WAV format mono PCM with 16kHz sample rate\n",
        "def convert_audio(input_audio_file, output_audio_file):\n",
        "    print(\"Converting audio to WAV format mono PCM with 16kHz sample rate...\")\n",
        "    audio = AudioSegment.from_file(input_audio_file)\n",
        "    audio = audio.set_channels(1)  # Convert to mono\n",
        "    audio = audio.set_frame_rate(16000)  # Set sample rate to 16kHz\n",
        "    audio.export(output_audio_file, format=\"wav\")\n",
        "    print(f\"Audio converted to {output_audio_file}\")\n",
        "\n",
        "# Function to transcribe audio using Whisper\n",
        "def transcribe_audio_whisper(audio_file):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_file)\n",
        "    return result['text']\n",
        "\n",
        "# Function to add line breaks to transcript\n",
        "def format_transcript(transcript, max_length=80):\n",
        "    words = transcript.split()\n",
        "    formatted_transcript = \"\"\n",
        "    current_line = \"\"\n",
        "\n",
        "    for word in words:\n",
        "        if len(current_line) + len(word) + 1 > max_length:\n",
        "            formatted_transcript += current_line + \"\\n\"\n",
        "            current_line = word\n",
        "        else:\n",
        "            if current_line:\n",
        "                current_line += \" \" + word\n",
        "            else:\n",
        "                current_line = word\n",
        "\n",
        "    if current_line:\n",
        "        formatted_transcript += current_line\n",
        "\n",
        "    return formatted_transcript\n",
        "\n",
        "# Main function to generate transcript\n",
        "def generate_transcript(video_file):\n",
        "    temp_audio_file = \"temp_audio.mp3\"\n",
        "    final_audio_file = \"final_audio.wav\"\n",
        "\n",
        "    # Extract audio from video\n",
        "    extract_audio(video_file, temp_audio_file)\n",
        "    # Convert audio to WAV format mono PCM with 16kHz sample rate\n",
        "    convert_audio(temp_audio_file, final_audio_file)\n",
        "\n",
        "    # Transcribe the entire audio file using Whisper\n",
        "    print(\"Transcribing audio file...\")\n",
        "    transcript = transcribe_audio_whisper(final_audio_file)\n",
        "\n",
        "    # Clean up temporary audio files\n",
        "    os.remove(temp_audio_file)\n",
        "    os.remove(final_audio_file)\n",
        "    print(\"Temporary files cleaned up.\")\n",
        "\n",
        "    # Format transcript with line breaks\n",
        "    formatted_transcript = format_transcript(transcript)\n",
        "\n",
        "    return formatted_transcript\n",
        "\n",
        "# Example usage in Jupyter Notebook or Google Colab\n",
        "video_file = \"/content/260 - Sorting Strings.mp4\"  # Replace with your video file path\n",
        "\n",
        "print(\"Generating transcript...\")\n",
        "transcript = generate_transcript(video_file)\n",
        "print(\"Transcript generated:\")\n",
        "print(transcript)\n",
        "\n",
        "# Optionally save the transcript to a file\n",
        "with open(\"transcript.txt\", \"w\") as f:\n",
        "    f.write(transcript)\n",
        "print(\"Transcript saved to transcript.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOI6MDyvbHD9",
        "outputId": "f0a442e6-93b8-45c8-f305-c78c5f35d21c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating transcript...\n",
            "Extracting audio from video...\n",
            "MoviePy - Writing audio in temp_audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Audio extracted to temp_audio.mp3\n",
            "Converting audio to WAV format mono PCM with 16kHz sample rate...\n",
            "Audio converted to final_audio.wav\n",
            "Transcribing audio file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temporary files cleaned up.\n",
            "Transcript generated:\n",
            "The next thing we're going to take a look at is how we can sort in array of\n",
            "strings. So I'm going to update my data array. I'm going to change it to T,\n",
            "capital A, lowercase A, capital B and lowercase B. Just a little bit ago before\n",
            "we introduced this comparator function, I told you that by default JavaScript is\n",
            "going to take all the elements inside an array, turn them into strings, and then\n",
            "compare them. So that might lead you to believe that JavaScript can sort in\n",
            "array of strings really well. Once again, not quite the case. So let me\n",
            "demonstrate that to you very quickly. I'm going to remove the comparator\n",
            "function because this one is really only designed to work with numbers. So I'm\n",
            "going to try calling data.sort and I'm going to see what I get back. So I'm\n",
            "going to run that and I get back something that definitely looks like it has\n",
            "changed, but it's not quite what I think I would be looking for if I was sorting\n",
            "in array of strings. I see all the capital letters first, then the lowercase\n",
            "letters. And I don't know about you, but personally, I would really expect to\n",
            "see all the A's, whether they are uppercase or lowercase, then the B's and then\n",
            "everything after that. So once again, the default sorting behavior is not quite\n",
            "working out for us. And if we fix this, we're going to put in once again, a\n",
            "comparator function to tell sort exactly how we want to sort our data. Now the\n",
            "sorting function or the comparator function we had just used was designed to\n",
            "work with numbers. So we need to put in a slightly different implementation to\n",
            "tell sort how to work with strings. All right, I'm going to receive the\n",
            "arguments a and b. And here's what we're going to do this time. I'm going to\n",
            "return a dot locale compare B. Notice that this is locale. It is not local. So\n",
            "there's an E between the L and the capital C right there. This is a built in\n",
            "function that belongs to all strings in JavaScript. It allows us to compare two\n",
            "strings. And it's going to return a number of negative one, zero or positive\n",
            "one. So this is a function that is kind of specifically made to help us compare\n",
            "strings in JavaScript and be used inside of a sort compare function. Let's try\n",
            "running this and just see if it solves our issue. And there we go. So now we've\n",
            "got a sorted result that makes a lot more sense. I've got all the a's and then\n",
            "all the b's and then everything after that. So no longer are we having to worry\n",
            "about uppercase or lowercase or anything. All right, so we've now got a good\n",
            "idea on how we can sort numbers and how we can sort strings. So we're going to\n",
            "start to take a look at one last variation and that is how do we sort and array\n",
            "of objects.\n",
            "Transcript saved to transcript.txt\n"
          ]
        }
      ]
    }
  ]
}